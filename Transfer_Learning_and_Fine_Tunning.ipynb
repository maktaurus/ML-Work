{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL/GW6FCN1omq0mK4iuDr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maktaurus/ML-Work/blob/main/Transfer_Learning_and_Fine_Tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Transfer Learning**\n",
        "\n",
        "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task.\n",
        "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n"
      ],
      "metadata": {
        "id": "gAPbPba-MQFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the model from keras"
      ],
      "metadata": {
        "id": "tK4X3wfTHywy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "metadata": {
        "id": "_mBsWnBIMLSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, Specifty the parameters. Use weights \"imagenet\" and input_shape of image for your desired problem.\n",
        "Then freeze the layers so weights are not updated.\n"
      ],
      "metadata": {
        "id": "jbC2ZGa9M5Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(250,250,3))\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "INHi0vjmODbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Check the model summary\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "sJ9_mVYROxWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "By pulling the summary of the model you can see that it is a very deep network. You can then select up to which point of the network you want to use. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application.\n"
      ],
      "metadata": {
        "id": "PVqEGSdtO_Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.layers.Input(shape=(None,None,3))\n",
        "x = tf.keras.layers.RandomBrightness(0.2)(input)\n",
        "x = base_model(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "output = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(input, output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TD1IQVpJPYZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way, where you want to select the layers from the network by specifying the names of layers."
      ],
      "metadata": {
        "id": "pMUxpnDGoZWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_maps = [layer.output for layer in base_model.layers if layer.name in (\"activation_58\",\"activation_59\")]"
      ],
      "metadata": {
        "id": "ETO6xftmoFiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR check if the layer is isinstance of the layer class"
      ],
      "metadata": {
        "id": "0yaQP9oVpC1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_maps = [layer.output for layer in base_model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
        "feature_maps"
      ],
      "metadata": {
        "id": "pPPGhpB8pKRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(base_model.input, feature_maps)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_pmpGFYlphXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way, is by taking a specific layer in the network and taking its output as last layer in network. So the model will not extract much."
      ],
      "metadata": {
        "id": "LUx4creZqEEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_layer = base_model.get_layer(\"activation_74\").output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(extracted_layer)\n",
        "output = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(base_model.input, output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "aYyyPY8aqB7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}