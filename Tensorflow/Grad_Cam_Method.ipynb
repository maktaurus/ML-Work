{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxCHpwuW42PHK+Z8A1GmZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maktaurus/ML-Work/blob/main/Grad_Cam_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient-weighted Class Activation Mapping (Grad-CAM)**\n",
        "**Grad-Cam is a visual explanation algorithm.**\n",
        "From a high-level, we take an image as input and create a model that is cut off at the layer for which we want to create a Grad-CAM heat-map. We attach the fully-connected layers for prediction. We then run the input through the model, grab the layer output, and prediction. Next, we find the gradient of the output of our desired model layer w.r.t. the model prediction. From there, we take sections of the gradient which contribute to the prediction, reduce, resize, and rescale so that the heat-map can be overlaid with the original image.\n"
      ],
      "metadata": {
        "id": "5bbLOcn5hzKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "In below code we create a function which will take image and convert that image which can be fed as per model requirement."
      ],
      "metadata": {
        "id": "4XoRxYaHnBs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8IPMis0KKmg"
      },
      "outputs": [],
      "source": [
        "def img_array(img_path, size):\n",
        "  image = load_img(img_path, target_size=(size,size,3))\n",
        "  img_arry = img_to_array(image)\n",
        "  norm_img = normalize_layer(img_arry)\n",
        "  # We add a dimension to transform our array into a \"batch\"\n",
        "  # of size (1, 250, 250, 3)\n",
        "  img_dims = tf.expand_dims(norm_img, axis=0)\n",
        "  return img_dims"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Grad-Cam model**\n",
        "Below function will create a grad-cam model which has following parameters:  \n",
        "1.   img_array - of size desired for model\n",
        "2.   model - name of the trained model\n",
        "3.   layer_name - Name of the layer on which we want Grad-Cam heatmap\n",
        "4.   pred_index - optional, index value of class. can be provided in situation when in a image there are more than 1 classes and we want to check if that object is present in image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "43v3HpWGnlyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Grad_Cam(model_name, layer_name, img, pred_index=None):\n",
        "  # First, we create a model that maps the input image to the activations\n",
        "  # of the last conv layer as well as the output predictions\n",
        "  grad_model = tf.keras.Model(model_name.input, [model_name.get_layer(layer_name).output, model_name.output])\n",
        "\n",
        "  # Then, we compute the gradient of the top predicted class for our input image\n",
        "  # with respect to the activations of the last conv layer\n",
        "  with tf.GradientTape() as tape:\n",
        "    last_conv_layer_output, pred = grad_model(img)\n",
        "    if pred_index is None:\n",
        "      pred_index = np.argmax(pred)\n",
        "    class_channel = pred[:,pred_index]\n",
        "    dog_breed = class_name[pred_index]\n",
        "    print(dog_breed)\n",
        "\n",
        "  # This is the gradient of the output neuron (top predicted or chosen)\n",
        "  # with regard to the output feature map of the last conv layer\n",
        "  grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "  # This is a vector where each entry is the mean intensity of the gradient\n",
        "  # over a specific feature map channel\n",
        "  pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "\n",
        "  # We multiply each channel in the feature map array\n",
        "  # by \"how important this channel is\" with regard to the top predicted class\n",
        "  # then sum all the channels to obtain the heatmap class activation\n",
        "  heatmap = last_conv_layer_output[0] @ pooled_grads[...,tf.newaxis]\n",
        "  heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "  # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "  heatmap = tf.nn.relu(heatmap).numpy()\n",
        "  return heatmap"
      ],
      "metadata": {
        "id": "gyr2gUyWnlFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Superimposed Image Visualization**\n",
        "Below function will take the output heatmap from previous Grad-Cam model and imposes on orginal input image. This will tells us where our model is looking to make prediction."
      ],
      "metadata": {
        "id": "QmfndhWptBPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "def superimpose_image(heatmap, img_path, alpha=0.5):\n",
        "  img = tf.keras.utils.load_img(img_path)\n",
        "  img = tf.keras.utils.img_to_array(img)\n",
        "\n",
        "  heatmap = np.uint8(255*heatmap)\n",
        "  heatmap = np.uint8(255*heatmap)\n",
        "  jet = mpl.colormaps[\"jet\"]\n",
        "  jet_colors = jet(np.arange(256))[:,:3]\n",
        "  jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "  jet_heatmap = tf.keras.utils.array_to_img(jet_heatmap)\n",
        "  jet_heatmap = tf.image.resize(jet_heatmap, (img.shape[0],img.shape[1]))\n",
        "  jet_heatmap = tf.keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "  superimposed_img = jet_heatmap * alpha + img\n",
        "  superimposed_img = tf.keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "  return plt.imshow(superimposed_img)"
      ],
      "metadata": {
        "id": "qRtgm4TXtnz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the example, where we have loaded the Xception model and predicted the calss and its heatmap.\n",
        "Note: When using pretained model deactivate the last activation layer."
      ],
      "metadata": {
        "id": "Imw-mYO-2reW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.xception import Xception, decode_predictions, preprocess_input\n",
        "\n",
        "pretrained_model = Xception(weights=\"imagenet\")\n",
        "\n",
        "pretrained_model.layers[-1].activation = None\n"
      ],
      "metadata": {
        "id": "5jnDzBBL2LIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = preprocess_input(img_array(\"/content/testing/q19.jpg\",299))\n",
        "\n",
        "pred = pretrained_model.predict(img)\n",
        "\n",
        "print(decode_predictions(pred, top=2))\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "Zu3Jt9JN2Ofm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = img_array(\"/content/testing/q19.jpg\", 299)\n",
        "heatmap = Grad_Cam(pretrained_model, \"block14_sepconv2_act\", img,208)\n",
        "superimpose_image(heatmap,\"/content/testing/q19.jpg\",3)"
      ],
      "metadata": {
        "id": "7I7210Nq2RLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below Example, where you are using a pretained model trained on your custom dataset.\n",
        "Note: here you dont have to deactivate the last activation layer.\n",
        "Provide image size as desired by model"
      ],
      "metadata": {
        "id": "ELkELtLO2zzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = img_array(\"/content/testing/q19.jpg\", 299)\n",
        "heatmap = Grad_Cam(pretrained_model, \"block14_sepconv2_act\", img)\n",
        "superimpose_image(heatmap,\"/content/testing/q19.jpg\",1)"
      ],
      "metadata": {
        "id": "q17SkYEd2tJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
