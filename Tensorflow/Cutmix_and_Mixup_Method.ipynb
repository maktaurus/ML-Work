{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcfmXrkDya9et1tpGRMlp8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maktaurus/ML-Work/blob/main/Cutmix_and_Mixup_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CutMix and Mixup Augmentation Startegies\n",
        "**CutMix**:\n",
        "In CutMix augmentation we cut and paste random patches between the training images. The ground truth labels are mixed in proportion to the area of patches in the images. CutMix increases localization ability by making the model to focus on less discriminative parts of the object being classified and hence is also well suited for tasks like object detection."
      ],
      "metadata": {
        "id": "wftlTRHFurmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "CJrPpnc1PD6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "4W-w9qrxO3QQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, take the dataset and unbatch it and zip them to create a new dataset."
      ],
      "metadata": {
        "id": "FF8ocvMFOTDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train1 = train_df.shuffle(5400).unbatch()\n",
        "train2 = train_df.shuffle(5400).unbatch()\n",
        "mixed_data = tf.data.Dataset.zip((train1, train2))"
      ],
      "metadata": {
        "id": "FyTURVlEOW3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, Define the function with cutmix logic.\n",
        "In below function we have passed the two datasets. We create the coordinates for bounding boxes.\n",
        "\n",
        "\n",
        "1.   For X and Y coordinates we take the uniform distribution.\n",
        "2.   The, we create a lambda value from beta distribution for height and weidth of BB_BOXES.\n",
        "3.   Take square root of 1 - lambda and multiply it with image size.\n",
        "4.   For bounding boxes clip the output values between 0 and Image size.\n",
        "5.   Check if target height and target width is <= 0, if yes the keep the values equal to 1.\n",
        "6. The, pass these bounding boxes values to tf function crop_to_bounding_box to get the patch then add the padding to that patch.\n",
        "7.  The, repeat the same process the get the patch from image 2.\n",
        "8.  For final image: subtract the pad_image from image 1 and add the padded_image patch from image 2.\n",
        "9.  For new_label: Follow below new label line.\n",
        "\n"
      ],
      "metadata": {
        "id": "wACSkQ7cOiyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Cutmix(data1, data2):\n",
        "\n",
        "  (image1, label1), (image2, label2) = data1, data2\n",
        "  IMG_SIZE = 200\n",
        "\n",
        "  cut_x = tf.cast(tfp.distributions.Uniform(0,200).sample(1)[0], dtype=tf.int32)\n",
        "  cut_y = tf.cast(tfp.distributions.Uniform(0,200).sample(1)[0], dtype=tf.int32)\n",
        "\n",
        "  lamda = tfp.distributions.Beta(0.2,0.2)\n",
        "  lamda = lamda.sample(1)[0]\n",
        "\n",
        "  cut_h = tf.cast(IMG_SIZE * (tf.math.sqrt(1-lamda)), dtype=tf.int32)\n",
        "  cut_w = tf.cast(IMG_SIZE * (tf.math.sqrt(1-lamda)), dtype=tf.int32)\n",
        "\n",
        "  bbx1 = tf.clip_by_value(cut_x - cut_h//2, 0, IMG_SIZE)\n",
        "  bby1 = tf.clip_by_value(cut_y - cut_w//2, 0, IMG_SIZE)\n",
        "  bbx2 = tf.clip_by_value(cut_x + cut_h//2, 0, IMG_SIZE)\n",
        "  bby2 = tf.clip_by_value(cut_y + cut_w//2, 0, IMG_SIZE)\n",
        "\n",
        "  target_height = bbx2 - bbx1\n",
        "  if (target_height == 0):\n",
        "    target_height = 1\n",
        "  target_width = bby2 - bby1\n",
        "  if (target_width == 0):\n",
        "    target_width = 1\n",
        "\n",
        "  crop1 = tf.image.crop_to_bounding_box(image1, bbx1, bby1, target_height, target_width)\n",
        "  img_pad1 = tf.image.pad_to_bounding_box(crop1, bbx1,bby1, IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "  crop2 = tf.image.crop_to_bounding_box(image2, bbx1,bby1, target_height, target_width)\n",
        "  img_pad2 = tf.image.pad_to_bounding_box(crop2, bbx1,bby1, IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "  final_image = image1 - img_pad1 +img_pad2\n",
        "  lamda = tf.cast(1-(target_width*target_height)/(IMG_SIZE*IMG_SIZE), dtype=tf.float32)\n",
        "  new_label = lamda*tf.cast(label1, dtype=tf.float32) + (1-lamda)*tf.cast(label2, dtype=tf.float32)\n",
        "\n",
        "  return final_image, new_label"
      ],
      "metadata": {
        "id": "MIugAIc1OhZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "map the above function to the dataset. Shuffle the date."
      ],
      "metadata": {
        "id": "_jtNh_0We0o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixup_data = mixed_data.shuffle(5000).map(Cutmix)"
      ],
      "metadata": {
        "id": "3v8Qo1kWe4pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch the above dataset."
      ],
      "metadata": {
        "id": "Kt1P2CL_fBSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixup_data = mixup_data.batch(32)"
      ],
      "metadata": {
        "id": "q3JhMginfA4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixup Augmentation Method\n",
        "Mixup is a data augmentation technique that involves blending pairs of samples and their corresponding labels to create new synthetic training examples."
      ],
      "metadata": {
        "id": "dxBiQKGLfIrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup(data1, data2):\n",
        "  # unpack the datasets\n",
        "  (image1, label1), (image2, label2) = data1, data2\n",
        "  # create a beta distribution value called lamda\n",
        "  lamda = tfp.distributions.Beta(0.2,0.2).sample(1)[0]\n",
        "\n",
        "  new_image = lamda*image1 + (1-lamda)*image2\n",
        "  new_label = lamda*label1 + (1-lamda)*label2\n",
        "\n",
        "  return new_image, new_label"
      ],
      "metadata": {
        "id": "2XuVg50_g8al"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}
